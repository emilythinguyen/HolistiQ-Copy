# -*- coding: utf-8 -*-
"""FormCheck.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KckO_bvTghhLxlo9OPWHYpigacJiJaYb
"""

!pip install mediapipe opencv-python numpy moviepy

import cv2
import mediapipe as mp
import numpy as np
import moviepy.editor as mp_editor
import os
from google.colab import files

uploaded = files.upload()
video_path = list(uploaded.keys())[0]  # Get the uploaded file name
print(f"Uploaded file: {video_path}")

def extract_frames(video_path, interval=1):
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    frames = []
    count = 0

    while cap.isOpened():
        success, frame = cap.read()
        if not success:
            break
        if count % int(fps * interval) == 0:
            frames.append(frame)
        count += 1

    cap.release()
    return frames

frames = extract_frames(video_path, interval=1)  # Extract frames every second
print(f"Extracted {len(frames)} frames.")

mp_pose = mp.solutions.pose
pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)

def get_keypoints_from_frame(frame):
    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = pose.process(image_rgb)

    if results.pose_landmarks:
        keypoints = np.array([(lm.x, lm.y, lm.z) for lm in results.pose_landmarks.landmark])
        return keypoints
    else:
        return None

# Extract keypoints from the first frame
keypoints_list = [get_keypoints_from_frame(frame) for frame in frames if get_keypoints_from_frame(frame) is not None]
print(f"Extracted keypoints from {len(keypoints_list)} frames.")

def compare_keypoints(user_keypoints, reference_keypoints, threshold=0.1):
    diff = np.linalg.norm(user_keypoints - reference_keypoints)
    return diff < threshold, diff

# Load reference pose (Example: using the first frame as reference)
reference_keypoints = keypoints_list[0] if keypoints_list else None

if reference_keypoints is not None:
    feedback_list = []
    for user_keypoints in keypoints_list:
        is_correct, diff_score = compare_keypoints(user_keypoints, reference_keypoints)
        feedback_list.append(diff_score)
    print(f"Feedback Scores: {feedback_list}")
else:
    print("No valid reference keypoints found.")

def generate_feedback(diff_score):
    if diff_score < 0.05:
        return "✅ Perfect Form!"
    elif diff_score < 0.15:
        return "⚠️ Good, but minor improvements needed."
    else:
        return "❌ Needs Improvement! Check posture."

feedback_results = [generate_feedback(score) for score in feedback_list]
print(feedback_results)

import matplotlib.pyplot as plt

def draw_landmarks(frame):
    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = pose.process(image_rgb)
    if results.pose_landmarks:
        mp_drawing = mp.solutions.drawing_utils
        mp_drawing.draw_landmarks(image_rgb, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
    return image_rgb

# Show an image with pose detection
plt.figure(figsize=(8, 6))
plt.imshow(draw_landmarks(frames[0]))
plt.axis("off")
plt.show()